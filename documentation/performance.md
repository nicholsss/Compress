# Performance testing
The text file used in these tests is a copy of [James Joyce's Ulysses](http://www.gutenberg.org/files/4300/4300-h/4300-h.htm), sized approximatery 1.5 Mb. The random input is generated by java.util.Random().

The time in the following results includes both encoding and decoding.

## LZW

#### Dictionary size (text file)

| Dictionary size | input size | encoded size | encoded / input | time (us) |
|-----------------|------------|--------------|--------------|--------------------|
| 1024 | 1539934 | 2476797 | 1.61 | 149308 |
| 4096 | 1539934 | 1781934 | 1.16 | 149448 |
| 16384 | 1539934 | 1371456 | 0.89 | 215892 |
| 65536 | 1539934 | 1110366 | 0.72 | 337734 |
| 262144 | 1539934 | 939951 | 0.61 | 552215 |
| 1048576 | 1539934 | 895368 | 0.58 | 520640 |

Dictionary size quite clearly improves the compression ratio.

#### Input size (text file)

| Dictionary size | input size | encoded size | encoded / input | time (us) |
|-----------------|------------|--------------|--------------|--------------------|
| 65536 | 1024 | 1845 | 1.80 | 139 |
| 65536 | 2048 | 3228 | 1.58 | 209 |
| 65536 | 4096 | 5706 | 1.39 | 463 |
| 65536 | 8192 | 9807 | 1.20 | 921 |
| 65536 | 16384 | 17253 | 1.05 | 3612 |
| 65536 | 32768 | 30267 | 0.92 | 5925 |
| 65536 | 65536 | 54771 | 0.84 | 12010 |
| 65536 | 131072 | 102165 | 0.78 | 23531 |
| 65536 | 262144 | 186048 | 0.71 | 54870 |
| 65536 | 524288 | 376365 | 0.72 | 112682 |
| 65536 | 1048576 | 757074 | 0.72 | 225672 |

Filesizes of less than 50kb do not benefit much from LZW encoding.

#### Input size (random data)

| Dictionary size | input size | encoded size | encoded / input | time (us) |
|-----------------|------------|--------------|--------------|--------------------|
| 65536 | 4069 | 11865 | 2.92 | 356 |
| 65536 | 8192 | 23313 | 2.85 | 934 |
| 65536 | 16384 | 44343 | 2.71 | 3693 |
| 65536 | 32768 | 83094 | 2.54 | 12582 |
| 65536 | 65536 | 150816 | 2.30 | 41730 |
| 65536 | 131072 | 298452 | 2.28 | 91067 |
| 65536 | 262144 | 577404 | 2.20 | 178917 |
| 65536 | 524288 | 1153932 | 2.20 | 402056 |
| 65536 | 1048576 | 2307351 | 2.20 | 814690 |
| 65536 | 2097152 | 4613616 | 2.20 | 1638032 |
| 65536 | 4194304 | 9205434 | 2.19 | 3467541 |

The performance of the LZW is quite terrible with random data. Processing time is within n*log(n) but the compression ratio is poor to say the least.

## Huffman

Huffman produces clearly smaller files than LZW and the processing time is less than n*log(n). With random data the compression is very minimal, which is to be expected.

#### Input size (text file)

| input size | encoded size | encoded / input | time (us) |
|------------|--------------|--------------|--------------------|
| 4069 | 2457 | 0.60 | 6290 |
| 8192 | 4847 | 0.59 | 5654 |
| 16384 | 9551 | 0.58 | 3816 |
| 32768 | 19065 | 0.58 | 5449 |
| 65536 | 37939 | 0.58 | 7528 |
| 131072 | 75506 | 0.58 | 16096 |
| 262144 | 151669 | 0.58 | 16015 |
| 524288 | 304277 | 0.58 | 30324 |
| 1048576 | 606691 | 0.58 | 63008 |

#### Input size (random data)

| input size | encoded size | encoded / input | time (us) |
|------------|--------------|--------------|--------------------|
| 4069 | 4061 | 1.00 | 755 |
| 8192 | 8191 | 1.00 | 1230 |
| 16384 | 16385 | 1.00 | 1665 |
| 32768 | 32769 | 1.00 | 3450 |
| 65536 | 65537 | 1.00 | 6519 |
| 131072 | 131073 | 1.00 | 13431 |
| 262144 | 262145 | 1.00 | 24876 |
| 524288 | 524289 | 1.00 | 54277 |
| 1048576 | 1048577 | 1.00 | 99903 |
| 2097152 | 2097153 | 1.00 | 201453 |
